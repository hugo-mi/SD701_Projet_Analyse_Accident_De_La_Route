# SD701_Projet : Analyse d'un dataset d'accident de la route

**SD-701 : Projet de Data Mining**
_Analyse d‚Äôune base de donn√©es des accidents corporels de la circulation routi√®res_

## Sommaire


**1. Pr√©sentation du projet** <br>
**2. Objectif du projet** <br>
**3. Pr√©sentation du Dataset** <br>
**4. Pre-processing** <br>
**5. Exploration des donn√©es** <br>
**6. S√©lection des variables** <br>
**7. Application de l'algorithme Apriori (r√®gles d'associations)** <br>
**8. Application de l'algorithme Regression Logistique** <br>
**9. Conclusion & Discusion** <br>
**10. Requirements** <br>

## 1/ Pr√©sentation du projet

Dans le cadre du projet SD 701 nous souhaitons analyser une base de donn√©es des accidents corporels de la circulation routi√®res. 
En appliquant diff√©rentes m√©thodes de DataMining sur un ensemble de jeux de donn√©es relatifs aux accidents de la route nous souhaitons d√©terminer les facteurs qui influencent la gravit√© d‚Äôun accident. 
Le contexte de l‚Äô√©tude pourrait √™tre la suivante : 
Il s‚Äôav√®re que la plupart des personnes impliqu√©es dans un accident de la route ne sont pas bless√©s ou ne pr√©sentent que des blessures artificielles. Cependant, il se peut que des personnes gravement bless√©es n√©cessitent une prise en charge √† l‚Äôh√¥pital. Dans une situation de crise sanitaire, o√π tous les h√¥pitaux se retrouvent en surcharge de patients, il peut √™tre utile de diminuer les accidents graves admis en soins intensifs. Pour ce faire, une campagne de pr√©vention s‚Äôappuyant sur les facteurs influen√ßant la gravit√© pourrait aider a diminuer le nombre d‚Äôaccidents graves. 
Pour conna√Ætre les facteurs influen√ßant la gravit√© d‚Äôun accident, l‚Äôoption retenu serait de diminuer la probabilit√© qu‚Äôune personne ait un accident sachant que cette derni√®re √† d√©j√† eu un accident. (Formule de Bayes). En ce sens conna√Ætre les facteurs influen√ßant la gravit√© des accidents permettraient des diminuer la probabilit√© qu‚Äôune personne soit hospitalis√©e. 


## 2/ Objectif du projet

L'objectif de ce projet est de d√©terminer les facteurs influen√ßant la gravit√© des accidents. Sur la base de cette analyse l‚Äôagence r√©gional de sant√© pourra alors fixer les orientations de sa future campagne nationale de lutte contre les accidents de la route. 


## 3/ Pr√©sentation du ¬´ Dataset ¬ª

Pour chaque accident corporel (soit un accident survenu sur une voie ouverte √† la circulation publique, impliquant au moins un v√©hicule et ayant fait au moins une victime ayant n√©cessit√© des soins), des saisies d‚Äôinformation d√©crivant l‚Äôaccident sont effectu√©es par l‚Äôunit√© des forces de l‚Äôordre (police, gendarmerie, etc.) qui est intervenue sur le lieu de l‚Äôaccident. Ces saisies sont rassembl√©es dans une fiche intitul√©e bulletin d‚Äôanalyse des accidents corporels. L‚Äôensemble de ces fiches constitue le fichier national des accidents corporels de la circulation dit " Fichier BAAC1" administr√© par l‚ÄôObservatoire national interminist√©riel de la s√©curit√© routi√®re "ONISR". Les bases de donn√©es, extraites du fichier BAAC, r√©pertorient l'int√©gralit√© des accidents corporels de la circulation intervenus durant une ann√©e pr√©cise en France m√©tropolitaine ainsi que les d√©partements d‚ÄôOutre-mer (Guadeloupe, Guyane, Martinique, La R√©union et Mayotte depuis 2012) avec une description simplifi√©e. Cela comprend des informations de localisation de l‚Äôaccident, telles que renseign√©es ainsi que des informations concernant les caract√©ristiques de l‚Äôaccident et son lieu, les v√©hicules impliqu√©s et leurs victimes.
Description des bases de donn√©es annuelles des accidents corporels de la circulation routi√®re - Ann√©es de 2005 √† 2018

Source Dataset : data.gouv.fr (minist√®re de l‚Äôint√©rieur)

‚Ä¢	https://www.data.gouv.fr/fr/datasets/bases-de-donnees-annuelles-des-accidents-corporels-de-la-circulation-routiere-annees-de-2005-a-2019/

Notre base de donn√©es est compos√©e de 4 fichiers csv :


‚Ä¢	**Caract√©ristique.csv** (58440 lignes) 

o	D√©crit les circonstances g√©n√©rales de l‚Äôaccident (types de collisions, luminosit√©, date)

![](https://github.com/hugo-mi/SD701_Projet_Analyse_Accident_De_La_Route/blob/development/img/carac_table.png)


‚Ä¢	**Lieux.csv** (58440 lignes)

o	D√©crit le lieu principal de l‚Äôaccident (cat√©gorie route, nb de voies, r√©gime de circulation, surface de la chauss√©e,‚Ä¶)

![](https://github.com/hugo-mi/SD701_Projet_Analyse_Accident_De_La_Route/blob/development/img/lieux_table.png)

‚Ä¢	**V√©hicules.csv** (100710 lignes)

o	D√©crit les v√©hicules impliqu√©s dans l‚Äôaccident (n¬∞ plaque immatriculations, type de v√©hicule, localisation du choc, man≈ìuvre,‚Ä¶)

![](https://github.com/hugo-mi/SD701_Projet_Analyse_Accident_De_La_Route/blob/development/img/vehic_table.png)


‚Ä¢	**Usagers.csv** (132978 lignes)

o	D√©crit les usagers impliqu√©s dans l‚Äôaccident (place de l‚Äôusager dans le v√©hicule, gravit√©, trajet de l‚Äôusager,‚Ä¶)

![](https://github.com/hugo-mi/SD701_Projet_Analyse_Accident_De_La_Route/blob/development/img/usag_table.png)

Chacune des variables contenues dans une rubrique est reli√©e aux variables des autres rubriques. Le n¬∞ d'identifiant de l‚Äôaccident (Cf. **"_Num_Acc_"**) pr√©sent dans ces 4 rubriques permet d'√©tablir un lien entre toutes les variables qui d√©crivent un accident. Quand un accident comporte plusieurs v√©hicules, il est √©galement possible de relier chaque v√©hicule √† ses occupants. Ce lien est fait par la variable **_Num_veh_**.

## 4/ Pre-processing

L'objectif de la phase de pre-processing est d'√©tudier la distrution des valeurs de chaque covariable afin d'effectuer un choix sur les variables √† garder et celle √† rejeter et ce tout en prenant en compte le contexte de notre √©tude. Il s'av√®re que pour la plupart des variables ont √©t√© re-encod√©es en suivant la strat√©gie one-hot encoding. 

Voici un exemple pour le r√©-encodage de la variable **_catu_** de la table **_Usagers_**

![](https://github.com/hugo-mi/SD701_Projet_Analyse_Accident_De_La_Route/blob/development/img/one_hot_encoding.png)

Les choix que nous avons entrepris pour r√©-encoder chacune des variables sont d√©crits dans le notebook **Projet_EGVD_PreProcessing**

**Distribution des variables de la table **_Caract√©ristique_**

![](https://github.com/hugo-mi/SD701_Projet_Analyse_Accident_De_La_Route/blob/development/img/distrib_table_carac1.png)

![](https://github.com/hugo-mi/SD701_Projet_Analyse_Accident_De_La_Route/blob/development/img/distrib_table_carac2.png)

**Distribution des variables de la table **_Lieux_**

![](https://github.com/hugo-mi/SD701_Projet_Analyse_Accident_De_La_Route/blob/development/img/distrib_table_lieux1.png)

![](https://github.com/hugo-mi/SD701_Projet_Analyse_Accident_De_La_Route/blob/development/img/distrib_table_lieux2.png)

**Distribution des variables de la table **_Usagers_**

![](https://github.com/hugo-mi/SD701_Projet_Analyse_Accident_De_La_Route/blob/development/img/distrib_table_usag.png)

**Distribution des variables de la table V√©hicules**

![](https://github.com/hugo-mi/SD701_Projet_Analyse_Accident_De_La_Route/blob/development/img/distrib_table_vehic1.png)

![](https://github.com/hugo-mi/SD701_Projet_Analyse_Accident_De_La_Route/blob/development/img/distrib_table_vehic2.png)


**Jeu de donn√©es nettoy√©**

![](https://github.com/hugo-mi/SD701_Projet_Analyse_Accident_De_La_Route/blob/development/img/dataset_cleaned.png)

## 5/ Exploration des donn√©es

Pour la section fouille de donn√©es nous avons choisi d'effectuer des analyses descriptives plus pouss√©es qui sont les suivantes

### 1√®re Visualisation : Carte de France interactive du nombre d\'accident par d√©partement en 2019

![](https://github.com/hugo-mi/SD701_Projet_Analyse_Accident_De_La_Route/blob/development/img/acc_dep.png)

**Interpr√©tation :**
A travers cette visualisation nous constatons que c'est en r√©gion √Æle de france que se produit le plus d'accident. Sans surprise la carte met en lumi√®re le fait que c'est dans les d√©partements o√π la population est la plus √©lev√© que se produit le plus d'accident. (Bouches-du-rh√¥nes, Rh√¥ne, Haut de Seine, Essone, Seine St Denis, Paris)

A l'inverse dans les r√©gions les moins denses en termes de population, le nombre d'accident y ait beaucoup plus faible.

### 2√®me Visualisation : Carte de France interactive pour localiser tous les accidents d'un d√©partement en particulier en 2019

![](https://github.com/hugo-mi/SD701_Projet_Analyse_Accident_De_La_Route/blob/development/img/carte_acc.png)

**Interpr√©tation :**
Encore une fois ce graphique confirme l'interpr√©ation que nous avons faites juste avant. Ce sont dans les endroits o√π la densit√© de population est la plus forte que se produit le plus d'accident. A noter toutefois que cela ne signifie pas que ce sont dans ces endroits les plus peupl√©s que se r√©alisent les accidents les plus graves.

### 3√®me Visualisation : Evolution du nombre des accidents en 2019 en fonction de la saison

![](https://github.com/hugo-mi/SD701_Projet_Analyse_Accident_De_La_Route/blob/development/img/acc_saison.png)

**Interpr√©tation :**
Au regard de l'histogramme nous observons, que c'est en √©t√© que se produit le plus d'accident. Cependant la diff√©rence du nombre d'accident entre l'√©t√©, l'automne et le printemps n'est pas marquante contairement √† la saison d'hiver. En effet, le delta du nombre d'accident entre l'√©t√© et l'hiver est cons√©quent. (4000 accidents de moins en hiver qu'en √©t√©)

### 4√®me Visualisation : Evolution du nombre des accidents en 2019

![](https://github.com/hugo-mi/SD701_Projet_Analyse_Accident_De_La_Route/blob/development/img/evolution_acc_2019.png)

**Interpr√©tation :**
En se fiant √† la moyenne des accidents par mois (courbe orange), nous remarquons que de d√©but Janvier √† mi Mai, le nombre des accidents augmentent. Toutefois on constate que ce nombre stagne de d√©but F√©vrier jusqu'√† mi Mai.

Par ailleurs de mi Mai √† mi Juillet ao√ªt nous assistons √† une augmentation consid√©rable du nombre d'accident puis l'inverse de produit de mi Juillet √† fin Ao√ªt. cela peut √™tre contre-intuitif car c'est √† ce moment de l'ann√©e que nous assistons aux grands chass√©s crois√©es entre d'un c√¥t√© les retours de vancance et de l'autre les d√©parts en vacance. On peut donc en d√©duire que le nombre d'accident entre le d√©but des vancances scolaires jusqu'√† mi-juillet est bien sup√©rieur qu'√† la fin des vacances scolaire (baisse non n√©gligeable du nombre d'accident entre mi Ao√ªt et d√©but Septembre).

A la rentr√©e scolaire nous constatons une augmentation du nombre d'accident. En fin d'ann√©e nous observons une baisse du nombre des accidents

**Conclusion de phase d'analyse :**
A travers cette analyse exploratoire, nous avons observ√© que c'est pendant la p√©riode d'Hiver que nous avons le moins d'accident et ce malgr√© le fait que les conditions m√©t√©orologiques soient mauvaises (neige, verglas, pluie,...) durant cette p√©riode de l'ann√©e.

Enfin, ce sont dans les endroits dans lesquels la densit√© de population est la plus forte que se produit le plus d'accident. Maintenant, il nous reste √† confirmer si ce sont dans ces r√©gions de la France que se produit les accidents les plus grave, c'est ce que nous allons tenter d'observer √† l'aide d'outil de machine learning

## 6/ S√©lection des variables

La s√©lection des variables est une √©tape important dans la chaine de cr√©ation de valeurs √† partir de donn√©es car elle permet de centr√© notre √©tude pour nous concentr√© uniquement les donn√©es ayant un impact significatif sur notre variable cible. 
En g√©n√©ral, il est recommand√© d'√©viter d'avoir des variables corr√©l√©es dans un jeu de donn√©es. En effet, un groupe de features fortement corr√©l√©es n'apportera pas d'informations suppl√©mentaires (ou juste tr√®s peu), mais augmentera la complexit√© de l'algorithme, augmentant ainsi le risque d'erreurs.
De plus la multicolin√©arit√© rend difficile l'interpr√©tation de nos coefficients et r√©duit la capacit√© de notre mod√®le √† identifier des variables ind√©pendantes statistiquement significatives.
Nous chercherons donc √† supprimer les variables fortement corr√©l√©s √† l'aide de la librairie python **_featurewiz_**. 
La matrice de corr√©lation est la suivante : 

![](https://github.com/hugo-mi/SD701_Projet_Analyse_Accident_De_La_Route/blob/development/img/matrice_corr.png)

Ensuite nous avons appliqu√© l'algorithme **_featurewiz _**est une biblioth√®que de python qui permet de trouver les meilleures caract√©ristiques dans notre ensemble de donn√©es si nous lui donnons un dataframe et le nom de la variable cible. Il fera ce qui suit :

- Il supprime automatiquement les caract√©ristiques fortement corr√©l√©es (la limite est fix√©e √† 0,70 mais nous pouvons la changer dans l'argument d'entr√©e).

- Si plusieurs caract√©ristiques sont corr√©l√©es entre elles, laquelle supprimer ? Dans un tel conflits, l'algorithme supprimera la caract√©ristique ayant le **mutual information score** le plus faible.

- Pour finir l'algorithme fera une s√©lection r√©cursive des caract√©ristiques en utilisant l'algorithme XGBoost pour trouver les meilleures caract√©ristiques en utilisant XGBoost.

Le r√©sultat de **_featurewiz _** est le suivant : 

![](https://github.com/hugo-mi/SD701_Projet_Analyse_Accident_De_La_Route/blob/development/img/featurewize_output.png)

![](https://github.com/hugo-mi/SD701_Projet_Analyse_Accident_De_La_Route/blob/development/img/featurewize_output1.png)

![](https://github.com/hugo-mi/SD701_Projet_Analyse_Accident_De_La_Route/blob/development/img/featurewize_output2.png)

**La liste des features en sortie de notre algorithme _featurewize_**

![](https://github.com/hugo-mi/SD701_Projet_Analyse_Accident_De_La_Route/blob/development/img/featurewize_output3.png)

Ensuite, pour appliquer notre  **ùëÖ√©ùëîùëüùëíùë†ùë†ùëñùëúùëõ   ùêøùëúùëîùëñùë†ùë°ùëñùëûùë¢ùëí**  et  l'algorithme **ùê¥ùëÉùëüùëñùëúùëüùëñ** nous souhaitons conserver uniquement 10 variables. Pour cela utilisons une Wrapper methods, en particulier de la **_RFE _** (acronyme pour Recursive Feature Elimination).
Le principe est simple : on fournit un mod√®le √† l'algorithme **_RFE _** (ici LogisticRegression), qui est ajust√© sur le jeu de donn√©es complet. L'importance de chaque feature est estim√©e et il supprime la ou les features les moins importantes, puis il recommence. Une fois le nombre de features cible atteint, on retourne le jeu de features qui a fourni le meilleur r√©sultat sur le jeu d'entrainement.
RFE est un algorithme de s√©lection de caract√©ristiques de type wrapper. Cela signifie qu'un algorithme d'apprentissage automatique diff√©rent est fourni et utilis√© au c≈ìur de la m√©thode, est envelopp√© (wrapped) par **_RFE _** et utilis√© pour aider √† s√©lectionner les fonctionnalit√©s.

Techniquement, **_RFE _** est un algorithme de s√©lection de caract√©ristiques de style wrapper qui utilise √©galement la s√©lection de caract√©ristiques bas√©e sur un filtre en interne.

**_RFE_** fonctionne en recherchant un sous-ensemble de fonctionnalit√©s en commen√ßant par toutes les fonctionnalit√©s du jeu de donn√©es d'apprentissage et en supprimant avec succ√®s les fonctionnalit√©s jusqu'√† ce que le nombre souhait√© reste.

Ceci est r√©alis√© en ajustant l'algorithme d'apprentissage automatique utilis√© dans le noyau du mod√®le, en classant les fonctionnalit√©s par importance, en supprimant les fonctionnalit√©s les moins importantes et en r√©ajustant le mod√®le. Ce processus est r√©p√©t√© jusqu'√† ce qu'un nombre sp√©cifi√© de fonctionnalit√©s reste.

Notre s√©lection final des 10 meilleurs features pour nos mod√®les est la suivante : 

![](https://github.com/hugo-mi/SD701_Projet_Analyse_Accident_De_La_Route/blob/development/img/wrapper.png)

## 7/ Application de l'algorithme Apriori (r√®gles d'associations)

Afin de r√©pondre √† l'objectif de notre √©tude qui on le rappel est de trouver les facteurs aggravant d'un accident, nous avons choisi d'appliquer l'algorithme Apriori. En utilisant cet algorithme nous esp√©rons pouvoir d√©terminer les ensembles des √©l√©ments fr√©quents causant des accidents graves. 
Pour ce faire, il proc√®de en identifiant les √©l√©ments individuels fr√©quents dans la base de donn√©es et en les √©tendant √† des ensembles d'√©l√©ments de plus en plus grands tant que ces ensembles d'√©l√©ments apparaissent suffisamment souvent dans la base de donn√©es.
Les itemsets fr√©quents d√©termin√©s par **Apriori ** peuvent √™tre utilis√©s pour d√©terminer des r√®gles d'association qui mettent en √©vidence des tendances g√©n√©rales dans la base de donn√©es : cela a des applications dans des domaines tels que  l'analyse du panier de commandes pour un site de e-commerce.

L'algorithme Apriori fait intervenir, 3 m√©triques qui sont les suivantes : 

**Le support :** il repr√©sente la fiabilit√©. Ce crit√®re permet de fixer un seuil en dessous duquel les r√®gles ne sont pas consid√©r√©es comme fiables. le support est utilis√© pour mesurer l'abondance ou la fr√©quence (souvent interpr√©t√©e comme une signification ou une importance) d'un ensemble d'√©l√©ments dans une base de donn√©es. Il est n√©c√©ssaire de fixer un seuil de support minimal √† respecter pour √©viter de s√©lectionner des r√®gles d‚Äôassociation qui seraient trop rares. 
Le support se calcul de la mani√®re suivante :

![](https://github.com/hugo-mi/SD701_Projet_Analyse_Accident_De_La_Route/blob/development/img/support.png)

**La confiance :** elle repr√©sente la pr√©cision de la r√®gle et peut √™tre vue comme la probabilit√© conditionnelle Conf(A -> C) = P(A|C). En clair La confiance d'une r√®gle A -> C est la probabilit√© de voir le cons√©quent dans une transaction √©tant donn√© qu'elle contient aussi l'ant√©c√©dent. La m√©trique n'est ni sym√©trique ni dirig√©e ; par exemple, la confiance pour A -> C est diff√©rente de la confiance pour C->A. La confiance est de 1 (maximale) pour une r√®gle A->C si le cons√©quent et l'ant√©c√©dent se produisent toujours ensemble. 
La confiance se calcul de la mani√®re suivante :

![](https://github.com/hugo-mi/SD701_Projet_Analyse_Accident_De_La_Route/blob/development/img/confidence.png)

**Le lift :** il caract√©rise l‚Äôint√©r√™t de la r√®gle, sa force. Un lift > 1 indique qu‚Äôil existe bien un lien entre les 2 √©l√©ments. La m√©trique lift est couramment utilis√©e pour mesurer combien de fois l'ant√©c√©dent et la cons√©quence d'une r√®gle A->C se produisent ensemble par rapport √† ce √† quoi nous nous attendrions s'ils √©taient statistiquement ind√©pendants. 
Le lift se calcul de la mani√®re suivante : 

![](https://github.com/hugo-mi/SD701_Projet_Analyse_Accident_De_La_Route/blob/development/img/lift.png)

Une ¬´ Bonne r√®gle ¬ª correspond √† un r√®gle dont le support et la confiance sont √©lev√©es. 

Nous avons utilis√© l'algorithme _**Apriori**_, de la librairie **_Apyori_**. Nous avons appliqu√© l'algorithme sur l'ensemble des variables qui ont √©t√© s√©lectionn√© par l'algorithme des s√©lections de variables. Ensuite, les valeurs de ces variables ont √©t√© r√©-encod√© en variable cat√©gorielle pour faciliter l'interpr√©tation du r√©sultat g√©n√©r√© par Apriori. A noter que chaque ligne de notre jeu de donn√©es correspond √† une transaction. Etant donn√© que nous souhaitons obtenir les r√®gles d'association qui ont comme cons√©quence notre variable cible binaire, nous avons s√©lectionn√© les lignes dont la valeur de de notre variable cible √©tait √©gale √† 1. 

Pour un support minimum fix√© √† 0.0045, une confiance minimum fix√© √† 0.2 et un lift minimum fix√© √† 4 et 2 √©l√©ments minimums engag√©s dans la transaction nous avons obtenu le r√©sultatc suivant:

![](https://github.com/hugo-mi/SD701_Projet_Analyse_Accident_De_La_Route/blob/development/img/output_reglog.png)

#### Interpr√©tation

L'algorithme, Apriori a √©t√© long √† executer sur nos machines. Par cons√©quent, nous n'avons pas pu executer l'algorithme Apriori sur l'ensemble de notre jeu de donn√©es car le temps de calcul est long. Nous nous sommes content√©s d'analyser les 200 premi√®res lignes de notre jeu de donn√©es ce qui nous apris 26 minutues or notre dataframe contient 21000 lignes. L'inconv√©nient est que cet √©chantillon peut ne pas √™tre repr√©sentatif de l'ensemble de note dataset.

Les informations que nous pouvons tirer du r√©sultat g√©n√©r√© par Apriori sont les suivantes : 
Premi√®rement lorsque plusieurs v√©hicules sont impliqu√©s dans un accident (entre 3 √† 5 v√©hicules) les cons√©quences d'un accident peuvent √™tre lourde jusqu'√† provoquer des bles√©es grave ou m√™me des morts. Cela se comprend facilement car d√®s lors qu'un certains nombres de v√©hicules sont engag√©s dans un accident plus les chocs sont violents. Cela correspond en fait √† un carambolage. 

Une autre information importante ressort du r√©sultat qui est que lorsque le choc entre les v√©hicules n'est pas un choc arri√®re, l'accident √† plus de probabilit√© d'√™tre grave. Il serait interessant alors de voir si le choc avant peut √™tre un facteur important dans le degr√© de gravit√© d'un accident. Enfin, en analysant le r√©sultat de l'algorithme nous nous apercevons qu'en province, les accidents sont plus g√©n√©ralement plus grave qu'en r√©gion √Æle de france. Cela peut s'expliquer par le fait que les routes d√©partementale la vitesse est plus elev√©e qu'en agglom√©ration (ville). Et cela est d'autant plus parlant car malgr√© le fait que notre analyse exploratoire montre qu'il se produit beaucoup plus d'accident en √Æle-de-france que dans l'ensemble des autres r√©gions, les accidents graves se situent hors de l'√Æle de france et plus g√©n√©ralement en dehors des villes (agglom√©ration). Cela signifie que la plupart des accidents graves se produisent sur des axes routier comme les d√©partementales et nationnales ou autoroute.

Par ailleurs en analysant le r√©sultat nous pouvons dire que lorsque les personnes impliqu√©es dans l'accident ne portent aucun √©quipement de protection individuelle, l'accident √† une forte probabilit√© d'engendrer des bl√©ss√©s graves et/ou des morts.

Enfin, la raison des trajets des personnes et notamment lorsqu'il s'agit d'un trajet loisir, semble renforcer la gravit√© d'un accident. On peut imaginer que lors d'un trajet loisir, le conducteur et moins concentr√© sur sa conduite et se laisse divertir facilement.

Globalement, les r√©sultats g√©n√©r√© par Apriori ne sont pas choquant mais ils auraient pu √™tre d√©duit facilement par un expert m√©tier dans le domaine de la s√©curit√© routi√®re. Autrement dit, l'algorithme Apriori ne nous a pas permis par de r√©v√©ler des facteurs dont on ignorait qu'ils pouvaient avoir un impact sur la gravit√© d'un accident. 

## 8/ Application  de l'algorithme Regression Logistique

L'algorithme Regression Logistique a √©t√© execut√© sur les variables s√©lectionn√©es par l'algorithme de s√©lection de variable. 

Pour trouver les meilleurs param√®tres √† fournir √† l'algorithme de Regression Logistiques, nous avons r√©alis√© un **Grid Search**
Souvent, les effets des hyperparam√®tres sur un mod√®le sont connus, mais comment d√©finir au mieux un hyperparam√®tre et des combinaisons d'hyperparam√®tres qui sont en interaction pour un jeu de donn√©es. Il existe souvent des heuristiques g√©n√©rales ou des r√®gles empiriques pour configurer les hyperparam√®tres.
Une bonne approche consiste √† rechercher diff√©rentes valeurs pour les hyperparam√®tres du mod√®le et choisir un sous-ensemble qui atteint les meilleures performances sur un ensemble de donn√©es, c'est ce qu'on appelle l' optimisation des hyperparam√®tres. Le r√©sultat d'une optimisation d'hyperparam√®tres est un ensemble unique d'hyperparam√®tres performants que nous pouvons utiliser pour configurer notre mod√®le.

Ensuite, nous pouvons d√©finir l'espace de recherche de nos hyperparam√®tres :

La r√©gression logistique n√©cessite trois param√®tres ¬´ C ¬ª, ¬´ p√©nalit√© ¬ª et ¬´ solver ¬ª qui seront optimis√©s par GridSearchCV. Nous avons donc d√©fini ces trois param√®tres sous forme de liste de valeurs dont GridSearchCV s√©lectionnera la meilleure valeur de param√®tre. 
√Ä la fin du grid search, le meilleur score et la configuration d'hyperparam√®tres ayant obtenu les meilleures performances sont retourn√©s. Nous pouvons voir que la meilleure configuration atteint une pr√©cision d'environ  74 , pour des valeurs sp√©cifiques du solveur √©gale √†  ùëôùëñùëèùëôùëõùëñùëíùëéùëü , pour une p√©nalit√©  ùëô2  et pour un  ùê∂=0.01 . C'est avec ce tunning des hyperparam√®tre que l'on atteint le score optimal.

*Les co√©fficients de la R√©gression Logistique son les suivants :** 

![](https://github.com/hugo-mi/SD701_Projet_Analyse_Accident_De_La_Route/blob/development/img/reg_log1.png)

**Analyse des co√©fficients de la r√©gression logistique**

![](https://github.com/hugo-mi/SD701_Projet_Analyse_Accident_De_La_Route/blob/development/img/reglog_formula.png)

**En passant les co√©fficients √† l'exponentielle pour am√©liorer leur interpr√™tation**

![](https://github.com/hugo-mi/SD701_Projet_Analyse_Accident_De_La_Route/blob/development/img/reg_log.png)

**regardons l'Odds ratio ou Rapport des cotes ( ùëÖùê∂ )**

![](https://github.com/hugo-mi/SD701_Projet_Analyse_Accident_De_La_Route/blob/development/img/Reglog2.png)

Au regard des r√©sultats de la r√©gression logistique, les accidents aux cons√©quences les plus lourdes : √™tre gravement bl√©ss√© ou d√©c√©d√©, concerne des accidents qui ont lieux en dehors des agglom√©rations sur des routes d√©partementales l√† o√π la vitesse est plus √©lev√©e qu'en ville.

Les rapports des cotes des co√©fficients  ùëüùëíùëî _ ùêºùê∑ùêπ  et  ùëéùëîùëî  nous indique qu'il y a moins d'accident grave en agglom√©ration et en √Æle de France, pourtant c'est l√† o√π la densit√© de la population est le plus √©lev√©. Cela peut s'expliquer par le fait que la vitesse est moins √©lev√© en ville ; ce qui cause moins d'accident grave.

Les individus qui conduisent des deux roues ressortent des accidents avec des blessure plus grave que ceux qui conduisent des v√©hicules. Les personnes √¢g√©s sont plus sensibles aux chocs et ressortent des accidents avec des bl√©ssure plus importantes.

## 9/ Conclusion & Discusion

A travers l'enseignement SD701, nous avons r√©alis√© conjointement un pr√©-traitement des donn√©es, une exploration des donn√©es avec la r√©alisation de diff√©rentes visualisation permettant de mieux comprendre le dataset ainsi que l'application de deux algorithmes de machine learning. 

L'algorithme de regression lin√©aire confirme les r√©sultats de l'algorithme Apriori notamment sur l'influence de la variable _choc_avant_. En effet, Apriori a montr√© que lorsque aucun choc arri√®re n'avait eu lieu lors de l'accident, la gravit√© de l'accident √©tait √©lev√©. Cela signifie qu'un choc avant renforce la gravit√© d'un accident et cela a √©t√© confirm√© par l'algorithme de Regression Logisitque (coefficient de _choc_avant_ > 1). Cela est confirm√© par le coefficient de la variable _circ_bidirectionnelle_ car lorsque la route est √† deux sens, le choc frontale se produit beaucoup plus souvent que sur une route √† sens unique. De plus intuitivement, on comprend que lorsqu'un accident √† lieu dans une voie √† 2 sens, le nombre de voitures impliqu√©s y est plus √©lev√©. Cela est confirm√© par l'algorithme Apriori qui met en exergue le fait que lorsque plusieurs v√©hicules participent √† un accident la probabilit√© que les cons√©quences de l'accident soient lourdes (bl√©ss√©s grave et/ou mort) est tr√®s √©lev√©e. Par ailleurs les deux algorithmes montrent que lorsque l'accident √† lieu sur des types de route se situant en dehors des grandes villes (hors agglom√©ration) comme les routes d√©partementales, la gravit√© de l'accident est plus √©lev√©e. En effet, Apriori a montr√© que les accidents les plus graves ont lieu en pronvince (hors Paris) et ce malgr√© le fait qu'il y ai beaucoup plus d'accident en R√©gion √Æle de France. Cela peut s'expliquer par le simple fait qu'en Ile de France, les routes d√©partementales se font plus rares qu'en province. 

Cependant, nous avons relev√© des incoh√©rences dans les donn√©es par exemple, le fait qu'il ait des vehicules avec une vitesse maximale autoris√© sup√©rieur √† 50km/h alors que le v√©hicule circule sur une autoroute dont la VMA est de 130 km/h. Ces erreurs semblent √™tre des erreurs de saisies, cependant nous n'avons pas voulu nous attarder sur la correction de ces erreurs car cela demanderait avant la confirmation d'un expert m√©tier dans le domaine de la s√©curit√© routi√®re. La qualit√© des donn√©es jouent un r√¥le important dans le pr√©cision des algorithmes de machine learning. Un adage bien connu dans le monde de la science des donn√©es permet de r√©sumer cela et stipule : Garbage in, garbage out. 

Enfin, tout au long de l'√©tape de pr√©-processing, nous avons du faire des choix pour aggr√©ger les diff√©rents datasets ainsi que pour s√©lectionner les variables √† garder et celle √† rejeter. Cette √©tape a occup√© la majeur partie de notre temps car nous devions nettoy√©, compil√© et joindre plusieurs dataframe entre eux. Nous avons voulu prendre le temps n√©c√©ssaire afin de nous assurer de la qualit√© de nos donn√©es avant d'y appliquer les diff√©rents algorithme de machine learning. 

## 10/ Requirements

``` python pip install pygal_maps_fr```

`pip install folium`

`pip install apyori`

`pip install featurewiz`
